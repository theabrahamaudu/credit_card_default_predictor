{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Low Default Portfolio in Austrialian Credit Data.\n",
    "This Notebook aims to tackle the `low default Portfolio problem in Credit scoring datasets`. Credit scoring in the means of computationally ascribing a number to a customer that depicts their creditworthiness (the confidence that the will repay a line of credit). Good customers get higher numbers while customers who default have lower mumbers, these numbers usually vary between 350 - 800. A good credit score can open various oppurtunities to loans, mortgages, and social oppurtunities, the reverse is the case for bad credit scores, as people with bad credit scores are subject to very high interest rates and limited social oppurtunities. It then becomes important to have a very good method for calculating credit scores, a method such as data science.\n",
    "Using data science as a tool for determining credit scores encounters a common problem called class imbalance, in the credit scoring domain it is referred to as the low default portfolio problem. It's a phenomenon where in a data set the number of defaulters are miniscule when compared to the number of non-defaulters, therefore skewing the distribution of the dataset overwhemling in one direction. This poses a problem for data science tools because it makes interpreting results much more difficult as the data is already skewed to one side, and any algorithm used to fit such that will have a bias towards the non-defaulters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    int64  \n",
      " 1   A2      690 non-null    float64\n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    int64  \n",
      " 4   A5      690 non-null    int64  \n",
      " 5   A6      690 non-null    int64  \n",
      " 6   A7      690 non-null    float64\n",
      " 7   A8      690 non-null    int64  \n",
      " 8   A9      690 non-null    int64  \n",
      " 9   A10     690 non-null    int64  \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    int64  \n",
      " 12  A13     690 non-null    int64  \n",
      " 13  A14     690 non-null    int64  \n",
      " 14  A15     690 non-null    int64  \n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 81.0 KB\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "import pandas as pd\n",
    "aus = pd.read_csv('Aussie Mach 2.csv')\n",
    "aus.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data set description\n",
    "The data set is the credit data applications. It can be downloaded from the UCI Machine learning repository, it has 6 numerical and 8 catergorical attributes. It contains 690 instances, some preprocessing has been done in advance as all the column names have been anonymized and all have numerical values. There are 44.5% of non-defaulters and 55.5% of defaulters in the class or target attribute.\n",
    "Further exploratory analysis of the data set is done below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.plotting.register_matplotlib_converters()#\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "corr_frame = aus.corr() #a dataframe of the correlations of each attribute with everyother attribute#\n",
    "sorted_corrs = corr_frame['A15'].abs().sort_values()#a vector of absolute values of correlations with the class attribute A15#\n",
    "strong_cores = sorted_corrs[sorted_corrs > 0.2]\n",
    "corrmat = aus[strong_cores.index].corr()\n",
    "# sns.heatmap(corrmat,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "The above cell examines how the features correlate with the target attribute A15. An arbitary cut off correlation value of > 0.2 was selected to sort out strongly correlated features. Then these features were further examined to see if any correlate woth the other in order to remove features that duplicate data. It can be seen that A8 correlates with A15 than any others and A9 and A10 correlate with each other, which means we will take one of them out. In this case we will retain A10 and discard A9 as A10 is a continous feature. `Implement with Genetic Algorithm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                    \tstd                    \tmin                    \tmax                    \n",
      "0  \t50    \t[0.77481674 3.54      ]\t[0.09331936 1.82439031]\t[0.60354449 1.        ]\t[0.85297888 6.        ]\n",
      "1  \t27    \t[0.84107089 4.68      ]\t[0.03218425 1.31818056]\t[0.71180241 1.        ]\t[0.85297888 6.        ]\n",
      "2  \t26    \t[0.85264178 4.82      ]\t[0.00112123 1.10797112]\t[0.84713424 3.        ]\t[0.85486425 6.        ]\n",
      "3  \t32    \t[0.85136802 4.6       ]\t[0.01121106 0.91651514]\t[0.7734917 2.       ]  \t[0.85486425 6.        ]\n",
      "4  \t27    \t[0.85341855 4.36      ]\t[0.00155977 0.59194594]\t[0.84720965 3.        ]\t[0.85486425 5.        ]\n",
      "5  \t28    \t[0.8544457 4.1      ]  \t[0.00123188 0.3       ]\t[0.84713424 4.        ]\t[0.85486425 5.        ]\n",
      "6  \t26    \t[0.85358296 3.96      ]\t[0.00868809 0.19595918]\t[0.79279789 3.        ]\t[0.85486425 4.        ]\n",
      "7  \t27    \t[0.85463122 3.94      ]\t[0.00113018 0.23748684]\t[0.84720965 3.        ]\t[0.85486425 4.        ]\n",
      "8  \t29    \t[0.85466742 4.02      ]\t[0.00081011 0.24413111]\t[0.85094268 3.        ]\t[0.85486425 5.        ]\n",
      "9  \t34    \t[0.85463273 4.        ]\t[0.00119408 0.2       ]\t[0.84720965 3.        ]\t[0.85486425 5.        ]\n",
      "10 \t35    \t[0.85482579 3.98      ]\t[0.00026923 0.14      ]\t[0.85294118 3.        ]\t[0.85486425 4.        ]\n",
      "11 \t29    \t[0.85362293 3.98      ]\t[0.00868929 0.14      ]\t[0.79279789 3.        ]\t[0.85486425 4.        ]\n",
      "12 \t26    \t[0.85358522 4.        ]\t[0.00868791 0.2       ]\t[0.79279789 3.        ]\t[0.85486425 5.        ]\n",
      "[False False  True  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = aus.A15\n",
    "strongly_corr_features = ['A3','A6','A7','A5','A10','A8']\n",
    "X = aus[strongly_corr_features]\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "aus_model_mach1 = linear_model.LogisticRegression()\n",
    "\n",
    "selector_1 = GeneticSelectionCV(aus_model_mach1, cv=10,\n",
    "                                  verbose = 1,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=6,\n",
    "                                  n_population=50,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=40,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.05,\n",
    "                                  tournament_size=3,\n",
    "                                  n_gen_no_change=10,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "chosen = selector_1.fit(train_X, train_y)\n",
    "indexed = chosen.support_# the chosen attributes were A7, A5, A10,A8\n",
    "print(indexed)\n",
    "type(indexed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "This being a dissertation research, the algorithm or model to be used has already been decided before experimentation thus experimentation just serves to test performance in context of other algorithms or models. The problem statement of the research is to show that this model can handle imbalance, more pointedly can deal with identifying defaulters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imblearn\n",
    "imblearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal Run\n",
    "To begin with, we will run all the algorithms to evaluated under ideal circumstances. That is, when the dataset is evenly distributed, to achieve this we will use SMOTE and UnderSampling to get the data to a 50:50 distribution. In Chawla's work he suggested that SMOTE be combined with some kind of undersampling method will improve model performance. The algorithms to be evaluated are: Zero R, Naive Bayes, SVM, MLP, LR, KNN, `proposed Ensemble (KNN, SVM, Decision Tree and Logistic Regression Meta)`, Decision Tree, Random Forest, Bayesian Networks, AdaBoost, Bagged Decision Tree. With the following metrics: Accuracy, AUCPRC, MCC,AUCROC and Time taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 383, 1: 307})\n",
      "Counter({0: 344, 1: 344})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "#Prepare Dataset\n",
    "y = aus.A15\n",
    "M = aus[['A7','A5','A10','A8']]\n",
    "counter_1 = Counter(y)\n",
    "print(counter_1)\n",
    "\n",
    "#oversample with SMOTE and combine with undersampling..\n",
    "oversample = SMOTE(sampling_strategy=0.9)\n",
    "undersample = RandomUnderSampler(sampling_strategy=1)\n",
    "config_size = [('o', oversample),('u',undersample)]\n",
    "pipeline = Pipeline(steps=config_size)\n",
    "M_ideal, y_ideal = pipeline.fit_resample(M, y)\n",
    "\n",
    "counter_2 = Counter(y_ideal)\n",
    "print(counter_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import matthews_corrcoef \n",
    "from sklearn.metrics import make_scorer\n",
    "scoring = {'Accuracy':'accuracy', 'AUCROC':'roc_auc',\n",
    "          'AUCPRC': 'average_precision',\n",
    "          'MCC':make_scorer(matthews_corrcoef)}\n",
    "\n",
    "def prop_ensemble(tof, c, k_neigh,criteria, depth ):\n",
    "    #Create Ensemble\n",
    "    level_0 = list()\n",
    "    level_0.append(('svm', SVC(kernel = tof, C = c)))\n",
    "    level_0.append(('knn', KNeighborsClassifier(n_neighbors=k_neigh)))\n",
    "    level_0.append(('cart', DecisionTreeClassifier(criterion =criteria, max_depth=depth)))\n",
    "    #define meta learner model\n",
    "    level_1 = LogisticRegression()\n",
    "    #define the stacking ensemble\n",
    "    modelled = StackingClassifier(estimators=level_0,\n",
    "                                  final_estimator=level_1, cv=10)\n",
    "    return modelled\n",
    "\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models(tof, c, k_neigh,criteria, depth):\n",
    "    #get a list of models to evaluate\n",
    "    mlmodels = dict()\n",
    "    mlmodels['lr'] = LogisticRegression()\n",
    "    mlmodels['knn'] = KNeighborsClassifier(n_neighbors=6)\n",
    "    mlmodels['cart'] = DecisionTreeClassifier()\n",
    "    mlmodels['svm'] = SVC()\n",
    "    mlmodels['naive_bayes'] = GaussianNB()\n",
    "    mlmodels['mlp'] = MLPClassifier()\n",
    "    mlmodels['randomforest'] = RandomForestClassifier()\n",
    "    mlmodels['adaboost'] = AdaBoostClassifier()\n",
    "    mlmodels['bagging'] = BaggingClassifier()\n",
    "    mlmodels['ensemble'] = prop_ensemble(tof, c, k_neigh,criteria, depth)\n",
    "    return mlmodels\n",
    "    \n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(algorithms, a, b):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tvalidate = cross_validate(algorithms, a, b, scoring=scoring,\n",
    "                             cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn validate\n",
    " \n",
    "# get the models to evaluate\n",
    "models = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 9,criteria = 'gini', depth = 4 )\n",
    "# evaluate the models and store results\n",
    "results_1, names_1 = list(), list()\n",
    "perform_1 = {}\n",
    "for name_1, algorithm_1 in models.items():\n",
    "    scored = evaluate_model(algorithm_1, M_ideal, y_ideal)\n",
    "    results_1.append(scored)\n",
    "    names_1.append(name_1)\n",
    "    perform_1[name_1]  = scored\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Notes\n",
    "The AUCPRC which calculates the Precision and Recall at each threshold using the trapezodial rule, can be gotten by using the `auc()` class. Alternatively, in theory calculating avergae precision should also preduce the same results or provide insight into the performance of algorithms. To check what metric names are available use `sorted(sklearn.metrics.SCORERS.keys())`. To find the keys within a multilevel dictionary `sorted(dict_name.keys())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_keeping(performances):\n",
    "    test_time_dict = {}\n",
    "    acc_dict = {}\n",
    "    aucroc_dict = {}\n",
    "    auprc_dict = {}\n",
    "    mcc_dict = {}\n",
    "\n",
    "    for key, values in performances.items():\n",
    "        test_time_dict[key] = values['fit_time'].mean()\n",
    "        acc_dict[key] = (values['test_Accuracy'].mean())*100\n",
    "        aucroc_dict[key] = values['test_AUCROC'].mean()\n",
    "        auprc_dict[key] = values['test_AUCPRC'].mean()\n",
    "        mcc_dict[key] = values['test_MCC'].mean()\n",
    "        \n",
    "    result_frame = pd.DataFrame({'Testing_Time':test_time_dict,\n",
    "                                    'Accuracy':acc_dict,\n",
    "                                    'AUCROC':aucroc_dict,\n",
    "                                    'AUCPRC':auprc_dict,\n",
    "                                    'MCC':mcc_dict})\n",
    "    return result_frame\n",
    "\n",
    "def analysis(learner, v, w):\n",
    "    results, names = list(), list()\n",
    "    dicty = {}\n",
    "    for name, algorithm in learner.items():\n",
    "        scores = evaluate_model(algorithm, v, w)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        dicty[name]  = scores\n",
    "        \n",
    "    return dicty\n",
    "\n",
    "complete_rec_1 = record_keeping(perform_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "For the ideal run with feature selection, all the algorithms performed well, In terms of testing times, the MLP spent the longest whilst the Naive Bayes spent the least time. `Accuracy` is pertinent in this run, as both classes are evenly represented, the best three algorithms in this regard were `Logistic Regression`, `Naive Bayes` and `ANN`. Same with the `MCC` metric with `SVM` coming in third as opposed to ANN. The story is different for the `AUCROC` and `AUCPRC` metric were the best performing algorithms were `Logistic Regression`, `Proposed Ensemble` and `ANN`. Although difference in performance was minimal, it can be inferred that the best algorithm in this run was `Logistic Regression` accross all metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rec_1.index.names = ['algorithms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Run\n",
    "In the real world Credit datasets are highly imbalanced and skewed with an over representation of non-defaulters, as such it is paramount that a model should at the very least retain discriminitive abilities as data becomes more and more skewed. The rest of the experiments have to do with assessing the performance of the afformentioned algorithms when the data is imbalanced 60/40, 70/30, 80/30, 90/10. To see which deals with imbalances the best. It is proposed that the developed ensemble will perform best over the imbalances. Realised that python packages do not allow for artificial imbalance. To fix soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing_Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUCROC</th>\n",
       "      <th>AUCPRC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>1.700119</td>\n",
       "      <td>88.017909</td>\n",
       "      <td>0.924332</td>\n",
       "      <td>0.943394</td>\n",
       "      <td>0.749849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.023833</td>\n",
       "      <td>87.599415</td>\n",
       "      <td>0.922062</td>\n",
       "      <td>0.940329</td>\n",
       "      <td>0.740451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>0.416864</td>\n",
       "      <td>87.424342</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>0.942411</td>\n",
       "      <td>0.738621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>0.838565</td>\n",
       "      <td>87.426170</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>0.950865</td>\n",
       "      <td>0.737594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.012652</td>\n",
       "      <td>87.251827</td>\n",
       "      <td>0.909902</td>\n",
       "      <td>0.926487</td>\n",
       "      <td>0.734376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.054634</td>\n",
       "      <td>87.216374</td>\n",
       "      <td>0.910774</td>\n",
       "      <td>0.923893</td>\n",
       "      <td>0.732571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.207286</td>\n",
       "      <td>86.867325</td>\n",
       "      <td>0.921727</td>\n",
       "      <td>0.934846</td>\n",
       "      <td>0.726727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <td>0.051182</td>\n",
       "      <td>86.692251</td>\n",
       "      <td>0.920160</td>\n",
       "      <td>0.926649</td>\n",
       "      <td>0.724362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cart</th>\n",
       "      <td>0.008842</td>\n",
       "      <td>86.100877</td>\n",
       "      <td>0.866992</td>\n",
       "      <td>0.867932</td>\n",
       "      <td>0.713168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.009445</td>\n",
       "      <td>84.082968</td>\n",
       "      <td>0.904998</td>\n",
       "      <td>0.913132</td>\n",
       "      <td>0.671094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Testing_Time   Accuracy    AUCROC    AUCPRC       MCC\n",
       "algorithms                                                         \n",
       "mlp               1.700119  88.017909  0.924332  0.943394  0.749849\n",
       "lr                0.023833  87.599415  0.922062  0.940329  0.740451\n",
       "randomforest      0.416864  87.424342  0.931100  0.942411  0.738621\n",
       "ensemble          0.838565  87.426170  0.935347  0.950865  0.737594\n",
       "naive_bayes       0.012652  87.251827  0.909902  0.926487  0.734376\n",
       "svm               0.054634  87.216374  0.910774  0.923893  0.732571\n",
       "adaboost          0.207286  86.867325  0.921727  0.934846  0.726727\n",
       "bagging           0.051182  86.692251  0.920160  0.926649  0.724362\n",
       "cart              0.008842  86.100877  0.866992  0.867932  0.713168\n",
       "knn               0.009445  84.082968  0.904998  0.913132  0.671094"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get dataset\n",
    "aus_60 = pd.read_csv('Aussie_60.csv')\n",
    "aus_60.rename(columns={\"'Class Value'\": 'A15'}, inplace=True)\n",
    "y = aus_60.A15\n",
    "X = aus_60[['A7','A5','A10','A8']]\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 9,criteria = 'gini', depth = 4 )\n",
    "# evaluate the models and store results\n",
    "perform_60 = analysis(models, X, y)\n",
    "\n",
    "complete_rec_60 = record_keeping(perform_60)\n",
    "\n",
    "complete_rec_60.index.names = ['algorithms']\n",
    "complete_rec_60\n",
    "complete_rec_60.sort_values(by=['MCC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset\n",
    "aus_70 = pd.read_csv('Aussie_70.csv')\n",
    "aus_70.rename(columns={\"'Class Value'\": 'A15'}, inplace=True)\n",
    "y = aus_70.A15\n",
    "X = aus_70[['A7','A5','A10','A8']]\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 9,criteria = 'gini', depth = 4 )\n",
    "# evaluate the models and store results\n",
    "\n",
    "perform_70 = analysis(models, X, y)    \n",
    "#keep results in a dataframe\n",
    "complete_rec_70 = record_keeping(perform_70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing_Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUCROC</th>\n",
       "      <th>AUCPRC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>0.446935</td>\n",
       "      <td>90.307374</td>\n",
       "      <td>0.942300</td>\n",
       "      <td>0.964936</td>\n",
       "      <td>0.767726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <td>0.063002</td>\n",
       "      <td>90.073204</td>\n",
       "      <td>0.932355</td>\n",
       "      <td>0.954384</td>\n",
       "      <td>0.762201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>1.239930</td>\n",
       "      <td>89.757423</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.752206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>2.188569</td>\n",
       "      <td>88.949721</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.961397</td>\n",
       "      <td>0.736543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cart</th>\n",
       "      <td>0.006935</td>\n",
       "      <td>88.820128</td>\n",
       "      <td>0.881837</td>\n",
       "      <td>0.915979</td>\n",
       "      <td>0.735890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.039478</td>\n",
       "      <td>88.976788</td>\n",
       "      <td>0.924094</td>\n",
       "      <td>0.959278</td>\n",
       "      <td>0.735551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.009515</td>\n",
       "      <td>88.872416</td>\n",
       "      <td>0.912331</td>\n",
       "      <td>0.951690</td>\n",
       "      <td>0.734868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.186100</td>\n",
       "      <td>88.741798</td>\n",
       "      <td>0.931824</td>\n",
       "      <td>0.961244</td>\n",
       "      <td>0.730676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.081934</td>\n",
       "      <td>88.637016</td>\n",
       "      <td>0.903678</td>\n",
       "      <td>0.939044</td>\n",
       "      <td>0.726683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.007793</td>\n",
       "      <td>87.721252</td>\n",
       "      <td>0.916682</td>\n",
       "      <td>0.943428</td>\n",
       "      <td>0.701883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Testing_Time   Accuracy    AUCROC    AUCPRC       MCC\n",
       "algorithms                                                         \n",
       "randomforest      0.446935  90.307374  0.942300  0.964936  0.767726\n",
       "bagging           0.063002  90.073204  0.932355  0.954384  0.762201\n",
       "ensemble          1.239930  89.757423  0.944414  0.970588  0.752206\n",
       "mlp               2.188569  88.949721  0.926829  0.961397  0.736543\n",
       "cart              0.006935  88.820128  0.881837  0.915979  0.735890\n",
       "lr                0.039478  88.976788  0.924094  0.959278  0.735551\n",
       "naive_bayes       0.009515  88.872416  0.912331  0.951690  0.734868\n",
       "adaboost          0.186100  88.741798  0.931824  0.961244  0.730676\n",
       "svm               0.081934  88.637016  0.903678  0.939044  0.726683\n",
       "knn               0.007793  87.721252  0.916682  0.943428  0.701883"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rec_70.index.names = ['algorithms']\n",
    "complete_rec_70\n",
    "complete_rec_70.sort_values(by=['MCC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset\n",
    "aus_80 = pd.read_csv('Aussie_80.csv')\n",
    "aus_80.rename(columns={\"'Class Value'\": 'A15'}, inplace=True)\n",
    "y = aus_80.A15\n",
    "X = aus_80[['A7','A5','A10','A8']]\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 9,criteria = 'gini', depth = 4 )\n",
    "# evaluate the models and store results\n",
    "perform_80 = analysis(models, X, y)\n",
    "    \n",
    "#keep results in a dataframe\n",
    "complete_rec_80 = record_keeping(perform_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing_Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUCROC</th>\n",
       "      <th>AUCPRC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>0.520944</td>\n",
       "      <td>93.195353</td>\n",
       "      <td>0.952801</td>\n",
       "      <td>0.982097</td>\n",
       "      <td>0.784573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <td>0.071673</td>\n",
       "      <td>92.847495</td>\n",
       "      <td>0.940647</td>\n",
       "      <td>0.975099</td>\n",
       "      <td>0.775717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cart</th>\n",
       "      <td>0.011427</td>\n",
       "      <td>91.994619</td>\n",
       "      <td>0.890600</td>\n",
       "      <td>0.950599</td>\n",
       "      <td>0.751535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>1.947726</td>\n",
       "      <td>92.097604</td>\n",
       "      <td>0.949159</td>\n",
       "      <td>0.983215</td>\n",
       "      <td>0.744420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.222184</td>\n",
       "      <td>91.471695</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.976501</td>\n",
       "      <td>0.726669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.011738</td>\n",
       "      <td>91.105476</td>\n",
       "      <td>0.914964</td>\n",
       "      <td>0.962773</td>\n",
       "      <td>0.711251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.010677</td>\n",
       "      <td>90.392125</td>\n",
       "      <td>0.913862</td>\n",
       "      <td>0.970675</td>\n",
       "      <td>0.707195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.134769</td>\n",
       "      <td>90.392216</td>\n",
       "      <td>0.893570</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.706485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3.035008</td>\n",
       "      <td>90.096804</td>\n",
       "      <td>0.931165</td>\n",
       "      <td>0.977669</td>\n",
       "      <td>0.698625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.034373</td>\n",
       "      <td>89.783395</td>\n",
       "      <td>0.924294</td>\n",
       "      <td>0.974295</td>\n",
       "      <td>0.682806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Testing_Time   Accuracy    AUCROC    AUCPRC       MCC\n",
       "algorithms                                                         \n",
       "randomforest      0.520944  93.195353  0.952801  0.982097  0.784573\n",
       "bagging           0.071673  92.847495  0.940647  0.975099  0.775717\n",
       "cart              0.011427  91.994619  0.890600  0.950599  0.751535\n",
       "ensemble          1.947726  92.097604  0.949159  0.983215  0.744420\n",
       "adaboost          0.222184  91.471695  0.932200  0.976501  0.726669\n",
       "knn               0.011738  91.105476  0.914964  0.962773  0.711251\n",
       "naive_bayes       0.010677  90.392125  0.913862  0.970675  0.707195\n",
       "svm               0.134769  90.392216  0.893570  0.956667  0.706485\n",
       "mlp               3.035008  90.096804  0.931165  0.977669  0.698625\n",
       "lr                0.034373  89.783395  0.924294  0.974295  0.682806"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rec_80.index.names = ['algorithms']\n",
    "complete_rec_80\n",
    "complete_rec_80.sort_values(by=['MCC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset\n",
    "aus_90 = pd.read_csv('Aussie_90.csv')\n",
    "aus_90.rename(columns={\"'Class Value'\": 'A15'}, inplace=True)\n",
    "y = aus_90.A15\n",
    "X = aus_90[['A7','A5','A10','A8']]\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 9,criteria = 'gini', depth = 4 )\n",
    "# evaluate the models and store results\n",
    "perform_90 = analysis(models, X, y)\n",
    "    \n",
    "#keep results in a dataframe\n",
    "complete_rec_90 = record_keeping(perform_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rec_90.index.names = ['algorithms']\n",
    "complete_rec_90\n",
    "complete_rec_90 = complete_rec_90.rename(columns = {'Testing_Time':'Testing_Time_90',\n",
    "                                    'Accuracy':'Accuracy_90',\n",
    "                                    'AUCROC':'AUCROC_90',\n",
    "                                    'AUCPRC':'AUCPRC_90',\n",
    "                                    'MCC':'MCC_90'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_analysis = pd.merge(complete_rec_1, complete_rec_60, on='algorithms',\n",
    "                suffixes=[\"_50\", \"_60\"])\n",
    "full_analysis = pd.merge(full_analysis, complete_rec_70, on='algorithms')\n",
    "full_analysis = pd.merge(full_analysis, complete_rec_80, on='algorithms',\n",
    "                suffixes=[\"_70\",\"_80\"])\n",
    "full_analysis = pd.merge(full_analysis, complete_rec_90, on='algorithms')\n",
    "# full_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Testing_Time_50', 'Testing_Time_60',\n",
    "           'Testing_Time_70', 'Testing_Time_80',\n",
    "           'Testing_Time_90', 'Accuracy_50',\n",
    "            'Accuracy_60', 'Accuracy_70',\n",
    "           'Accuracy_80', 'Accuracy_90',\n",
    "            'AUCROC_50',  'AUCROC_60',\n",
    "            'AUCROC_70',  'AUCROC_80',\n",
    "            'AUCROC_90', 'AUCPRC_50',\n",
    "           'AUCPRC_60', 'AUCPRC_70',\n",
    "            'AUCPRC_80', 'AUCPRC_90',\n",
    "            'MCC_50', 'MCC_60',\n",
    "          'MCC_70', 'MCC_80',\n",
    "          'MCC_90']\n",
    "df = full_analysis.reindex(columns=column_names)\n",
    "df = df.T\n",
    "df = df.rename_axis(\"Metrics\")\n",
    "df = df.rename_axis('Models', axis='columns')\n",
    "\n",
    "df.columns = ['LR', 'KNN', 'Decision Tree',\n",
    "           'SVM', 'Naive Bayes', 'MLP',\n",
    "           'Random Forest', 'AdaBoost',\n",
    "           'Bagged Decision Tree',\n",
    "           'Proposed Ensemble']\n",
    "aussie_table=df.copy()\n",
    "aussie_table.index = pd.MultiIndex.from_product([['Testing_Time', 'Accuracy',\n",
    "                                    'AUCROC','AUCPRC',\n",
    "                                    'MCC'], \n",
    "                                    [50, 60, 70, 80, 90]],\n",
    "                                    names=['metric', 'run'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The German Dataset seems to have some problems and since I cannot do a cost matrix for each algorithm yet. I will not use it in visualizations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data set description\n",
    "The data set is the German credit dataset. It can be downloaded from the UCI Machine learning repository, it contains 1000 instances. Originally it appears as a dataset with strings and intergers, but there is a numeric version alos abialble at the repository. Some preprocessing has been done in advance as all the column names have been anonymized and all have numerical values. There are 70% of non-defaulters and 30% of defaulters in the class or target attribute. Further exploratory analysis of the data set is done below. The dataset also  contains a cost amtrix for cost sensitive classification if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "german_new_dt = pd.read_csv('SouthGermanCredit.asc',sep=' ',delimiter=None, index_col=False,skipinitialspace=True)\n",
    "\n",
    "#rename the columns from german names to englsih name\n",
    "german_new_dt.rename(columns={'laufkont':'status','laufzeit':'duration',\n",
    "                              'moral':'credit_history','verw':'purpose',\n",
    "                              'hoehe':'amount','sparkfont':'savings',\n",
    "                              'beszeit':'employment_duration', 'rate':'installment_rate',\n",
    "                              'famges':'personal_status_sex', 'buerge':'other_debtors',\n",
    "                              'wohnzeit':'present_residence', 'verm':'property',\n",
    "                              'weitkred':'other_installment_plans', 'sparkont':'savings',\n",
    "                              'alter':'age', 'wohn':'housing','bishkred':'number_credits',\n",
    "                              'beruf':'job', 'pers':'people_liable', 'telef':'telephone',\n",
    "                              'gastarb':'foreign_worker','kredit':'class'\n",
    "    \n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count  Dtype\n",
      "---  ------                   --------------  -----\n",
      " 0   status                   1000 non-null   int64\n",
      " 1   duration                 1000 non-null   int64\n",
      " 2   credit_history           1000 non-null   int64\n",
      " 3   purpose                  1000 non-null   int64\n",
      " 4   amount                   1000 non-null   int64\n",
      " 5   savings                  1000 non-null   int64\n",
      " 6   employment_duration      1000 non-null   int64\n",
      " 7   installment_rate         1000 non-null   int64\n",
      " 8   personal_status_sex      1000 non-null   int64\n",
      " 9   other_debtors            1000 non-null   int64\n",
      " 10  present_residence        1000 non-null   int64\n",
      " 11  property                 1000 non-null   int64\n",
      " 12  age                      1000 non-null   int64\n",
      " 13  other_installment_plans  1000 non-null   int64\n",
      " 14  housing                  1000 non-null   int64\n",
      " 15  number_credits           1000 non-null   int64\n",
      " 16  job                      1000 non-null   int64\n",
      " 17  people_liable            1000 non-null   int64\n",
      " 18  telephone                1000 non-null   int64\n",
      " 19  foreign_worker           1000 non-null   int64\n",
      " 20  class                    1000 non-null   int64\n",
      "dtypes: int64(21)\n",
      "memory usage: 164.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_dt = german_new_dt\n",
    "german_dt.info()\n",
    "german_dt['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a dataframe of the correlations of each attribute with everyother attribute\n",
    "co_frame = german_dt.corr()\n",
    "\n",
    "#a vector of absolute values of correlations with the class attribute \n",
    "sorted_co = co_frame['class'].abs().sort_values()\n",
    "strong_co = sorted_co[sorted_co > 0.1]\n",
    "\n",
    "# a plot of the highly correlated attributes\n",
    "german_co = german_dt[strong_co.index].corr()\n",
    "sns.heatmap(german_co,cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = ['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', \n",
    "        'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap',\n",
    "        'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens',\n",
    "        'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges',\n",
    "        'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1',\n",
    "        'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu',\n",
    "        'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r',\n",
    "        'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu',\n",
    "        'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r',\n",
    "        'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral',\n",
    "        'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', \n",
    "        'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r',\n",
    "        'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r',\n",
    "        'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm',\n",
    "        'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix',\n",
    "        'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth',\n",
    "        'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', \n",
    "        'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern',\n",
    "        'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r',\n",
    "        'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r',\n",
    "        'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r',\n",
    "        'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r',\n",
    "        'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket',\n",
    "        'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r',\n",
    "        'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r',\n",
    "        'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted',\n",
    "        'twilight_shifted_r', 'viridis', 'viridis_r', 'vlag', 'vlag_r', 'winter', 'winter_r'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['savings', 'duration', 'status'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                    \tstd                    \tmin                    \tmax                    \n",
      "0  \t50    \t[0.70874667 2.12      ]\t[0.01242838 0.81584312]\t[0.68666667 1.        ]\t[0.73733333 3.        ]\n",
      "1  \t32    \t[-1199.36986667     2.46      ]\t[3.24984805e+03 9.21086315e-01]\t[-10000.      0.]      \t[0.75066667 4.        ]\n",
      "2  \t28    \t[0.72370667 2.62      ]        \t[0.01306201 0.52497619]        \t[0.688 1.   ]          \t[0.75066667 3.        ]\n",
      "3  \t23    \t[-999.33896    2.88   ]        \t[3.00022035e+03 6.52380257e-01]\t[-1.e+04  1.e+00]      \t[0.75066667 5.        ]\n",
      "4  \t29    \t[-999.33344    2.94   ]        \t[3.00022219e+03 6.13514466e-01]\t[-1.e+04  1.e+00]      \t[0.75066667 5.        ]\n",
      "5  \t35    \t[-1199.34357333     3.02      ]\t[3.24985776e+03 5.47357287e-01]\t[-1.e+04  2.e+00]      \t[0.75066667 5.        ]\n",
      "6  \t32    \t[-199.26536    2.98   ]        \t[1.40010495e+03 2.44131112e-01]\t[-1.e+04  2.e+00]      \t[0.75066667 4.        ]\n",
      "7  \t25    \t[-399.28058667    3.        ]  \t[1.95973864e+03 2.82842712e-01]\t[-1.e+04  2.e+00]      \t[0.75066667 4.        ]\n",
      "8  \t25    \t[0.75066667 3.        ]        \t[4.4408921e-16 0.0000000e+00]  \t[0.75066667 3.        ]\t[0.75066667 3.        ]\n",
      "9  \t32    \t[-599.29488    3.04   ]        \t[2.37504656e+03 2.80000000e-01]\t[-1.e+04  2.e+00]      \t[0.75066667 4.        ]\n",
      "10 \t29    \t[-199.26482667    3.        ]  \t[1.40010502e+03 2.00000000e-01]\t[-1.e+04  2.e+00]      \t[0.75066667 4.        ]\n",
      "11 \t29    \t[-399.27936    3.04   ]        \t[1.95973889e+03 1.95959179e-01]\t[-1.e+04  3.e+00]      \t[0.75066667 4.        ]\n",
      "[False False False False  True  True False  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate target column from other columns in the dataframe\n",
    "y = german_dt['class']\n",
    "\n",
    "#gather the features together and store as variable X\n",
    "all_columns = strong_co.index\n",
    "all_columns = all_columns[:-1]\n",
    "X = german_dt[all_columns]\n",
    "\n",
    "#split the features and target into train and test splits\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "german_model_mach1 = linear_model.LogisticRegression()\n",
    "\n",
    "selector_1 = GeneticSelectionCV(german_model_mach1, cv=10,\n",
    "                                  verbose = 1,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=3,\n",
    "                                  n_population=50,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=40,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.05,\n",
    "                                  tournament_size=3,\n",
    "                                  n_gen_no_change=10,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "chosen = selector_1.fit(train_X, train_y)\n",
    "indexed = chosen.support_\n",
    "print(indexed)\n",
    "type(indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_out = strong_co.drop('class')\n",
    "try_out[indexed].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal Run for German Dataset\n",
    "In this experiment as with the austrailian dataset, the data will be resampled using SMOTE and random undersampling techniques to resample the data such that the instances for defaulters are non-defaulters are equal. Then models will be trained on this dataset and this performance will serve as the basis or ideal situation performance. The algorithms run are the same from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['status', 'duration', 'credit_history', 'purpose', 'amount', 'savings',\n",
       "       'employment_duration', 'installment_rate', 'personal_status_sex',\n",
       "       'other_debtors', 'present_residence', 'property', 'age',\n",
       "       'other_installment_plans', 'housing', 'number_credits', 'job',\n",
       "       'people_liable', 'telephone', 'foreign_worker', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X2', 'X3'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = all_columns[:-1]\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 700, 2: 300})\n",
      "Counter({1: 630, 2: 630})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X2  X3\n",
       "0     12   2\n",
       "1     20   0\n",
       "2     30   2\n",
       "3     48   3\n",
       "4     15   4\n",
       "...   ..  ..\n",
       "1255   6   1\n",
       "1256  24   1\n",
       "1257  36   2\n",
       "1258  24   2\n",
       "1259  12   2\n",
       "\n",
       "[1260 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare Dataset\n",
    "c = german_dt.Class\n",
    "B = german_dt[all_columns]\n",
    "\n",
    "counter_3 = Counter(c)\n",
    "print(counter_3)\n",
    "\n",
    "#oversample with SMOTE and combine with undersampling..\n",
    "oversample_1 = SMOTE(sampling_strategy=0.9)\n",
    "undersample_1 = RandomUnderSampler(sampling_strategy=1)\n",
    "config_size = [('o', oversample_1),('u',undersample_1)]\n",
    "pipeline_1 = Pipeline(steps=config_size)\n",
    "B_ideal, c_ideal = pipeline_1.fit_resample(B, c)\n",
    "\n",
    "counter_4 = Counter(c_ideal)\n",
    "print(counter_4)\n",
    "B_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feature = B_ideal[\"X3\"]\n",
    "cat_features = cat_feature.values\n",
    "cate_feature = cat_features.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X2    0    1    2    3    4\n",
       "0     12  0.0  0.0  1.0  0.0  0.0\n",
       "1     20  1.0  0.0  0.0  0.0  0.0\n",
       "2     30  0.0  0.0  1.0  0.0  0.0\n",
       "3     48  0.0  0.0  0.0  1.0  0.0\n",
       "4     15  0.0  0.0  0.0  0.0  1.0\n",
       "...   ..  ...  ...  ...  ...  ...\n",
       "1255   6  0.0  1.0  0.0  0.0  0.0\n",
       "1256  24  0.0  1.0  0.0  0.0  0.0\n",
       "1257  36  0.0  0.0  1.0  0.0  0.0\n",
       "1258  24  0.0  0.0  1.0  0.0  0.0\n",
       "1259  12  0.0  0.0  1.0  0.0  0.0\n",
       "\n",
       "[1260 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(cate_feature))\n",
    "OH_cols_train.index = B_ideal.index\n",
    "B_OH = B_ideal.drop('X3', axis=1)\n",
    "B_ideals = pd.concat([B_OH, OH_cols_train], axis=1)\n",
    "B_ideals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B_ideals.columns = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "std_feature = B_ideals[\"X1\"]\n",
    "std_features = std_feature.values\n",
    "stde_feature = std_features.reshape(-1, 1)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('std_scaler', StandardScaler()),\n",
    "])\n",
    "B_idea = pd.DataFrame(num_pipeline.fit_transform(stde_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.194011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.044288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.593708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.313161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.085017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X2   X3   X4   X5   X6         0\n",
       "0     0.0  0.0  1.0  0.0  0.0 -0.833525\n",
       "1     1.0  0.0  0.0  0.0  0.0 -0.194011\n",
       "2     0.0  0.0  1.0  0.0  0.0  0.605381\n",
       "3     0.0  0.0  0.0  1.0  0.0  2.044288\n",
       "4     0.0  0.0  0.0  0.0  1.0 -0.593708\n",
       "...   ...  ...  ...  ...  ...       ...\n",
       "1255  0.0  1.0  0.0  0.0  0.0 -1.313161\n",
       "1256  0.0  1.0  0.0  0.0  0.0  0.125746\n",
       "1257  0.0  0.0  1.0  0.0  0.0  1.085017\n",
       "1258  0.0  0.0  1.0  0.0  0.0  0.125746\n",
       "1259  0.0  0.0  1.0  0.0  0.0 -0.833525\n",
       "\n",
       "[1260 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_idea.index = B_ideals.index\n",
    "B_ST = B_ideals.drop('X1', axis=1)\n",
    "B_ideals = pd.concat([B_ST, B_idea], axis=1)\n",
    "B_ideals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing_Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUCROC</th>\n",
       "      <th>AUCPRC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.025554</td>\n",
       "      <td>62.619048</td>\n",
       "      <td>0.686050</td>\n",
       "      <td>0.404937</td>\n",
       "      <td>0.254423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.009090</td>\n",
       "      <td>60.555556</td>\n",
       "      <td>0.658802</td>\n",
       "      <td>0.426638</td>\n",
       "      <td>0.228826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cart</th>\n",
       "      <td>0.005545</td>\n",
       "      <td>62.751323</td>\n",
       "      <td>0.686932</td>\n",
       "      <td>0.405563</td>\n",
       "      <td>0.257123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.079949</td>\n",
       "      <td>62.883598</td>\n",
       "      <td>0.679130</td>\n",
       "      <td>0.411185</td>\n",
       "      <td>0.259330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.005736</td>\n",
       "      <td>58.915344</td>\n",
       "      <td>0.678063</td>\n",
       "      <td>0.406903</td>\n",
       "      <td>0.221564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>2.818671</td>\n",
       "      <td>63.121693</td>\n",
       "      <td>0.683518</td>\n",
       "      <td>0.414467</td>\n",
       "      <td>0.264201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>0.596741</td>\n",
       "      <td>62.936508</td>\n",
       "      <td>0.685492</td>\n",
       "      <td>0.407345</td>\n",
       "      <td>0.261411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.295797</td>\n",
       "      <td>62.724868</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.406104</td>\n",
       "      <td>0.255512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <td>0.072163</td>\n",
       "      <td>62.857143</td>\n",
       "      <td>0.683783</td>\n",
       "      <td>0.406293</td>\n",
       "      <td>0.261072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>0.988518</td>\n",
       "      <td>62.645503</td>\n",
       "      <td>0.680894</td>\n",
       "      <td>0.412403</td>\n",
       "      <td>0.254146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Testing_Time   Accuracy    AUCROC    AUCPRC       MCC\n",
       "algorithms                                                         \n",
       "lr                0.025554  62.619048  0.686050  0.404937  0.254423\n",
       "knn               0.009090  60.555556  0.658802  0.426638  0.228826\n",
       "cart              0.005545  62.751323  0.686932  0.405563  0.257123\n",
       "svm               0.079949  62.883598  0.679130  0.411185  0.259330\n",
       "naive_bayes       0.005736  58.915344  0.678063  0.406903  0.221564\n",
       "mlp               2.818671  63.121693  0.683518  0.414467  0.264201\n",
       "randomforest      0.596741  62.936508  0.685492  0.407345  0.261411\n",
       "adaboost          0.295797  62.724868  0.692962  0.406104  0.255512\n",
       "bagging           0.072163  62.857143  0.683783  0.406293  0.261072\n",
       "ensemble          0.988518  62.645503  0.680894  0.412403  0.254146"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models_1 = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 10,criteria = 'entropy', depth = 2 )\n",
    "\n",
    "# evaluate the models and store results\n",
    "perform_german_1 = analysis(models_1, B_ideals, c_ideal)\n",
    "    \n",
    "#keep results in a dataframe\n",
    "german_rec_ideal = record_keeping(perform_german_1)\n",
    "german_rec_ideal.index.names = ['algorithms']\n",
    "german_rec_ideal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal Analysis\n",
    "In the ideal run for the german dataset, the dataset contained 630 values for defaulters and non defaulters. The results displayed in the table about are excellent but also counter intuitive. Most of the algorithms achieved an accuracy of 100% but vary in performance in Area under the Precision Recall Curve, where the max is 1 and minimum is zero. This suggests that something or some other arrangement within the data was learnt by the algorithms and this affected their performance. This will be further investigated in subsequent distributions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing_Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUCROC</th>\n",
       "      <th>AUCPRC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.009613</td>\n",
       "      <td>65.232832</td>\n",
       "      <td>0.684956</td>\n",
       "      <td>0.508227</td>\n",
       "      <td>0.236003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.003467</td>\n",
       "      <td>66.036693</td>\n",
       "      <td>0.681875</td>\n",
       "      <td>0.518705</td>\n",
       "      <td>0.260763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cart</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>70.090137</td>\n",
       "      <td>0.717562</td>\n",
       "      <td>0.476411</td>\n",
       "      <td>0.359771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.042818</td>\n",
       "      <td>62.180715</td>\n",
       "      <td>0.655311</td>\n",
       "      <td>0.519639</td>\n",
       "      <td>0.153221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.004156</td>\n",
       "      <td>64.720012</td>\n",
       "      <td>0.682131</td>\n",
       "      <td>0.509854</td>\n",
       "      <td>0.222988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.612007</td>\n",
       "      <td>64.404902</td>\n",
       "      <td>0.689374</td>\n",
       "      <td>0.507098</td>\n",
       "      <td>0.228278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>0.315664</td>\n",
       "      <td>70.574958</td>\n",
       "      <td>0.732363</td>\n",
       "      <td>0.471307</td>\n",
       "      <td>0.370232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.156433</td>\n",
       "      <td>70.434227</td>\n",
       "      <td>0.754242</td>\n",
       "      <td>0.469752</td>\n",
       "      <td>0.367790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <td>0.032955</td>\n",
       "      <td>70.003438</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.473537</td>\n",
       "      <td>0.357579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>0.504293</td>\n",
       "      <td>66.947637</td>\n",
       "      <td>0.712741</td>\n",
       "      <td>0.490180</td>\n",
       "      <td>0.287403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Testing_Time   Accuracy    AUCROC    AUCPRC       MCC\n",
       "algorithms                                                         \n",
       "lr                0.009613  65.232832  0.684956  0.508227  0.236003\n",
       "knn               0.003467  66.036693  0.681875  0.518705  0.260763\n",
       "cart              0.003000  70.090137  0.717562  0.476411  0.359771\n",
       "svm               0.042818  62.180715  0.655311  0.519639  0.153221\n",
       "naive_bayes       0.004156  64.720012  0.682131  0.509854  0.222988\n",
       "mlp               0.612007  64.404902  0.689374  0.507098  0.228278\n",
       "randomforest      0.315664  70.574958  0.732363  0.471307  0.370232\n",
       "adaboost          0.156433  70.434227  0.754242  0.469752  0.367790\n",
       "bagging           0.032955  70.003438  0.726061  0.473537  0.357579\n",
       "ensemble          0.504293  66.947637  0.712741  0.490180  0.287403"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare Dataset for 60/40\n",
    "german_60 = pd.read_csv('German Numeric 60.csv')\n",
    "c_60 = german_60.Class\n",
    "\n",
    "B_60 = german_60[all_columns]\n",
    "\n",
    "# get the models to evaluate\n",
    "models_1 = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 10,criteria = 'entropy', depth = 2 )\n",
    "\n",
    "# evaluate the models and store results\n",
    "perform_german_60 = analysis(models_1, B_60, c_60)\n",
    "    \n",
    "#keep results in a dataframe\n",
    "german_rec_60 = record_keeping(perform_german_60)\n",
    "german_rec_60.index.names = ['algorithms']\n",
    "german_rec_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the models to evaluate\n",
    "models_1 = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 10,criteria = 'entropy', depth = 2 )\n",
    "\n",
    "# evaluate the models and store results\n",
    "perform_german_70 = analysis(models_1, B, c)\n",
    "    \n",
    "#keep results in a dataframe\n",
    "german_rec_70 = record_keeping(perform_german_70)\n",
    "german_rec_70.index.names = ['algorithms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Dataset for 80/20\n",
    "german_80 = pd.read_csv('German Numeric 80.csv')\n",
    "c_80 = german_80.Class\n",
    "\n",
    "B_80 = german_80[all_columns]\n",
    "\n",
    "# get the models to evaluate\n",
    "models_1 = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 10,criteria = 'entropy', depth = 2 )\n",
    "\n",
    "# evaluate the models and store results\n",
    "perform_german_80 = analysis(models_1, B_80, c_80)\n",
    "    \n",
    "#keep results in a dataframe\n",
    "german_rec_80 = record_keeping(perform_german_80)\n",
    "german_rec_80.index.names = ['algorithms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing_Time_90</th>\n",
       "      <th>Accuracy_90</th>\n",
       "      <th>AUCROC_90</th>\n",
       "      <th>AUCPRC_90</th>\n",
       "      <th>MCC_90</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.016936</td>\n",
       "      <td>90.033333</td>\n",
       "      <td>0.699936</td>\n",
       "      <td>0.835157</td>\n",
       "      <td>0.094284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.006500</td>\n",
       "      <td>89.144444</td>\n",
       "      <td>0.785263</td>\n",
       "      <td>0.849818</td>\n",
       "      <td>0.130314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cart</th>\n",
       "      <td>0.005900</td>\n",
       "      <td>89.311111</td>\n",
       "      <td>0.845718</td>\n",
       "      <td>0.834729</td>\n",
       "      <td>0.189921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.120341</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.497895</td>\n",
       "      <td>0.885927</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.003567</td>\n",
       "      <td>88.944444</td>\n",
       "      <td>0.706311</td>\n",
       "      <td>0.834336</td>\n",
       "      <td>0.148803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>1.387405</td>\n",
       "      <td>89.900000</td>\n",
       "      <td>0.696772</td>\n",
       "      <td>0.835555</td>\n",
       "      <td>0.018030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>0.423898</td>\n",
       "      <td>89.566667</td>\n",
       "      <td>0.857833</td>\n",
       "      <td>0.817810</td>\n",
       "      <td>0.233667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.191314</td>\n",
       "      <td>90.044444</td>\n",
       "      <td>0.861879</td>\n",
       "      <td>0.797772</td>\n",
       "      <td>0.124158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <td>0.050970</td>\n",
       "      <td>89.433333</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>0.826876</td>\n",
       "      <td>0.232387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>1.306982</td>\n",
       "      <td>89.900000</td>\n",
       "      <td>0.815656</td>\n",
       "      <td>0.808373</td>\n",
       "      <td>0.081446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Testing_Time_90  Accuracy_90  AUCROC_90  AUCPRC_90    MCC_90\n",
       "algorithms                                                                \n",
       "lr                   0.016936    90.033333   0.699936   0.835157  0.094284\n",
       "knn                  0.006500    89.144444   0.785263   0.849818  0.130314\n",
       "cart                 0.005900    89.311111   0.845718   0.834729  0.189921\n",
       "svm                  0.120341    90.000000   0.497895   0.885927  0.000000\n",
       "naive_bayes          0.003567    88.944444   0.706311   0.834336  0.148803\n",
       "mlp                  1.387405    89.900000   0.696772   0.835555  0.018030\n",
       "randomforest         0.423898    89.566667   0.857833   0.817810  0.233667\n",
       "adaboost             0.191314    90.044444   0.861879   0.797772  0.124158\n",
       "bagging              0.050970    89.433333   0.852490   0.826876  0.232387\n",
       "ensemble             1.306982    89.900000   0.815656   0.808373  0.081446"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare Dataset for 90/10\n",
    "german_90 = pd.read_csv('German Numeric 90.csv')\n",
    "c_90 = german_90.Class\n",
    "\n",
    "B_90 = german_90[all_columns]\n",
    "\n",
    "# get the models to evaluate\n",
    "models_1 = get_models(tof = 'rbf', c = 1,\n",
    "                    k_neigh = 10,criteria = 'entropy', depth = 2 )\n",
    "\n",
    "# evaluate the models and store results\n",
    "perform_german_90 = analysis(models_1, B_90, c_90)\n",
    "    \n",
    "#keep results in a dataframe\n",
    "german_rec_90 = record_keeping(perform_german_90)\n",
    "german_rec_90.index.names = ['algorithms']\n",
    "german_rec_90\n",
    "german_rec_90 = german_rec_90.rename(columns = {'Testing_Time':'Testing_Time_90',\n",
    "                                    'Accuracy':'Accuracy_90',\n",
    "                                    'AUCROC':'AUCROC_90',\n",
    "                                    'AUCPRC':'AUCPRC_90',\n",
    "                                    'MCC':'MCC_90'})\n",
    "german_rec_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>MLP</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Bagged Decision Tree</th>\n",
       "      <th>Proposed Ensemble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Testing_Time</th>\n",
       "      <th>50</th>\n",
       "      <td>0.011434</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.044836</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.843754</td>\n",
       "      <td>0.297860</td>\n",
       "      <td>0.148712</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.621077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.042818</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.612007</td>\n",
       "      <td>0.315664</td>\n",
       "      <td>0.156433</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.504293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.012043</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.036015</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.581282</td>\n",
       "      <td>0.384651</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>0.037770</td>\n",
       "      <td>0.501271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.012034</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.055970</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.710321</td>\n",
       "      <td>0.410798</td>\n",
       "      <td>0.168612</td>\n",
       "      <td>0.043788</td>\n",
       "      <td>0.734696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.016936</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.120341</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>1.387405</td>\n",
       "      <td>0.423898</td>\n",
       "      <td>0.191314</td>\n",
       "      <td>0.050970</td>\n",
       "      <td>1.306982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Accuracy</th>\n",
       "      <th>50</th>\n",
       "      <td>64.947090</td>\n",
       "      <td>61.878307</td>\n",
       "      <td>64.259259</td>\n",
       "      <td>62.751323</td>\n",
       "      <td>63.280423</td>\n",
       "      <td>63.888889</td>\n",
       "      <td>64.206349</td>\n",
       "      <td>63.968254</td>\n",
       "      <td>64.074074</td>\n",
       "      <td>64.788360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>65.232832</td>\n",
       "      <td>66.036693</td>\n",
       "      <td>70.090137</td>\n",
       "      <td>62.180715</td>\n",
       "      <td>64.720012</td>\n",
       "      <td>64.404902</td>\n",
       "      <td>70.574958</td>\n",
       "      <td>70.434227</td>\n",
       "      <td>70.003438</td>\n",
       "      <td>66.947637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71.500000</td>\n",
       "      <td>67.133333</td>\n",
       "      <td>68.866667</td>\n",
       "      <td>70.200000</td>\n",
       "      <td>70.700000</td>\n",
       "      <td>71.633333</td>\n",
       "      <td>69.366667</td>\n",
       "      <td>71.233333</td>\n",
       "      <td>69.233333</td>\n",
       "      <td>69.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>79.888889</td>\n",
       "      <td>79.022222</td>\n",
       "      <td>78.911111</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>79.933333</td>\n",
       "      <td>79.244444</td>\n",
       "      <td>80.266667</td>\n",
       "      <td>79.155556</td>\n",
       "      <td>80.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90.033333</td>\n",
       "      <td>89.144444</td>\n",
       "      <td>89.311111</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>88.944444</td>\n",
       "      <td>89.900000</td>\n",
       "      <td>89.566667</td>\n",
       "      <td>90.044444</td>\n",
       "      <td>89.433333</td>\n",
       "      <td>89.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AUCROC</th>\n",
       "      <th>50</th>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.654586</td>\n",
       "      <td>0.700722</td>\n",
       "      <td>0.682796</td>\n",
       "      <td>0.694402</td>\n",
       "      <td>0.698602</td>\n",
       "      <td>0.698652</td>\n",
       "      <td>0.708764</td>\n",
       "      <td>0.697606</td>\n",
       "      <td>0.689951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.684956</td>\n",
       "      <td>0.681875</td>\n",
       "      <td>0.717562</td>\n",
       "      <td>0.655311</td>\n",
       "      <td>0.682131</td>\n",
       "      <td>0.689374</td>\n",
       "      <td>0.732363</td>\n",
       "      <td>0.754242</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.712741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.683397</td>\n",
       "      <td>0.614254</td>\n",
       "      <td>0.632040</td>\n",
       "      <td>0.643317</td>\n",
       "      <td>0.684984</td>\n",
       "      <td>0.685571</td>\n",
       "      <td>0.637302</td>\n",
       "      <td>0.688802</td>\n",
       "      <td>0.636183</td>\n",
       "      <td>0.644937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.693926</td>\n",
       "      <td>0.686375</td>\n",
       "      <td>0.739458</td>\n",
       "      <td>0.592491</td>\n",
       "      <td>0.697657</td>\n",
       "      <td>0.693861</td>\n",
       "      <td>0.748282</td>\n",
       "      <td>0.774921</td>\n",
       "      <td>0.739194</td>\n",
       "      <td>0.715537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.699936</td>\n",
       "      <td>0.785263</td>\n",
       "      <td>0.845718</td>\n",
       "      <td>0.497895</td>\n",
       "      <td>0.706311</td>\n",
       "      <td>0.696772</td>\n",
       "      <td>0.857833</td>\n",
       "      <td>0.861879</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>0.815656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AUCPRC</th>\n",
       "      <th>50</th>\n",
       "      <td>0.402161</td>\n",
       "      <td>0.428220</td>\n",
       "      <td>0.399915</td>\n",
       "      <td>0.408298</td>\n",
       "      <td>0.404811</td>\n",
       "      <td>0.402790</td>\n",
       "      <td>0.401616</td>\n",
       "      <td>0.401706</td>\n",
       "      <td>0.401876</td>\n",
       "      <td>0.406607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.508227</td>\n",
       "      <td>0.518705</td>\n",
       "      <td>0.476411</td>\n",
       "      <td>0.519639</td>\n",
       "      <td>0.509854</td>\n",
       "      <td>0.507098</td>\n",
       "      <td>0.471307</td>\n",
       "      <td>0.469752</td>\n",
       "      <td>0.473537</td>\n",
       "      <td>0.490180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.609014</td>\n",
       "      <td>0.656924</td>\n",
       "      <td>0.636384</td>\n",
       "      <td>0.625024</td>\n",
       "      <td>0.608345</td>\n",
       "      <td>0.608329</td>\n",
       "      <td>0.637709</td>\n",
       "      <td>0.609767</td>\n",
       "      <td>0.638866</td>\n",
       "      <td>0.630398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.710032</td>\n",
       "      <td>0.737655</td>\n",
       "      <td>0.713571</td>\n",
       "      <td>0.745290</td>\n",
       "      <td>0.709652</td>\n",
       "      <td>0.708929</td>\n",
       "      <td>0.700982</td>\n",
       "      <td>0.688111</td>\n",
       "      <td>0.708530</td>\n",
       "      <td>0.707971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.835157</td>\n",
       "      <td>0.849818</td>\n",
       "      <td>0.834729</td>\n",
       "      <td>0.885927</td>\n",
       "      <td>0.834336</td>\n",
       "      <td>0.835555</td>\n",
       "      <td>0.817810</td>\n",
       "      <td>0.797772</td>\n",
       "      <td>0.826876</td>\n",
       "      <td>0.808373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MCC</th>\n",
       "      <th>50</th>\n",
       "      <td>0.300088</td>\n",
       "      <td>0.240515</td>\n",
       "      <td>0.287119</td>\n",
       "      <td>0.256975</td>\n",
       "      <td>0.269833</td>\n",
       "      <td>0.280693</td>\n",
       "      <td>0.287098</td>\n",
       "      <td>0.282380</td>\n",
       "      <td>0.286584</td>\n",
       "      <td>0.297544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.236003</td>\n",
       "      <td>0.260763</td>\n",
       "      <td>0.359771</td>\n",
       "      <td>0.153221</td>\n",
       "      <td>0.222988</td>\n",
       "      <td>0.228278</td>\n",
       "      <td>0.370232</td>\n",
       "      <td>0.367790</td>\n",
       "      <td>0.357579</td>\n",
       "      <td>0.287403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.194953</td>\n",
       "      <td>0.082433</td>\n",
       "      <td>0.119018</td>\n",
       "      <td>0.116253</td>\n",
       "      <td>0.179344</td>\n",
       "      <td>0.211630</td>\n",
       "      <td>0.155779</td>\n",
       "      <td>0.199882</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.088062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.123845</td>\n",
       "      <td>0.121806</td>\n",
       "      <td>0.144181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181599</td>\n",
       "      <td>0.121202</td>\n",
       "      <td>0.177087</td>\n",
       "      <td>0.160948</td>\n",
       "      <td>0.177052</td>\n",
       "      <td>0.076044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.094284</td>\n",
       "      <td>0.130314</td>\n",
       "      <td>0.189921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148803</td>\n",
       "      <td>0.018030</td>\n",
       "      <td>0.233667</td>\n",
       "      <td>0.124158</td>\n",
       "      <td>0.232387</td>\n",
       "      <td>0.081446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         LR        KNN  Decision Tree        SVM  Naive Bayes  \\\n",
       "metric       run                                                                \n",
       "Testing_Time 50    0.011434   0.003667       0.003601   0.044836     0.003067   \n",
       "             60    0.009613   0.003467       0.003000   0.042818     0.004156   \n",
       "             70    0.012043   0.003657       0.002469   0.036015     0.004125   \n",
       "             80    0.012034   0.003667       0.003467   0.055970     0.003700   \n",
       "             90    0.016936   0.006500       0.005900   0.120341     0.003567   \n",
       "Accuracy     50   64.947090  61.878307      64.259259  62.751323    63.280423   \n",
       "             60   65.232832  66.036693      70.090137  62.180715    64.720012   \n",
       "             70   71.500000  67.133333      68.866667  70.200000    70.700000   \n",
       "             80   79.888889  79.022222      78.911111  80.000000    79.666667   \n",
       "             90   90.033333  89.144444      89.311111  90.000000    88.944444   \n",
       "AUCROC       50    0.696175   0.654586       0.700722   0.682796     0.694402   \n",
       "             60    0.684956   0.681875       0.717562   0.655311     0.682131   \n",
       "             70    0.683397   0.614254       0.632040   0.643317     0.684984   \n",
       "             80    0.693926   0.686375       0.739458   0.592491     0.697657   \n",
       "             90    0.699936   0.785263       0.845718   0.497895     0.706311   \n",
       "AUCPRC       50    0.402161   0.428220       0.399915   0.408298     0.404811   \n",
       "             60    0.508227   0.518705       0.476411   0.519639     0.509854   \n",
       "             70    0.609014   0.656924       0.636384   0.625024     0.608345   \n",
       "             80    0.710032   0.737655       0.713571   0.745290     0.709652   \n",
       "             90    0.835157   0.849818       0.834729   0.885927     0.834336   \n",
       "MCC          50    0.300088   0.240515       0.287119   0.256975     0.269833   \n",
       "             60    0.236003   0.260763       0.359771   0.153221     0.222988   \n",
       "             70    0.194953   0.082433       0.119018   0.116253     0.179344   \n",
       "             80    0.123845   0.121806       0.144181   0.000000     0.181599   \n",
       "             90    0.094284   0.130314       0.189921   0.000000     0.148803   \n",
       "\n",
       "                        MLP  Random Forest   AdaBoost  Bagged Decision Tree  \\\n",
       "metric       run                                                              \n",
       "Testing_Time 50    0.843754       0.297860   0.148712              0.038334   \n",
       "             60    0.612007       0.315664   0.156433              0.032955   \n",
       "             70    0.581282       0.384651   0.205749              0.037770   \n",
       "             80    0.710321       0.410798   0.168612              0.043788   \n",
       "             90    1.387405       0.423898   0.191314              0.050970   \n",
       "Accuracy     50   63.888889      64.206349  63.968254             64.074074   \n",
       "             60   64.404902      70.574958  70.434227             70.003438   \n",
       "             70   71.633333      69.366667  71.233333             69.233333   \n",
       "             80   79.933333      79.244444  80.266667             79.155556   \n",
       "             90   89.900000      89.566667  90.044444             89.433333   \n",
       "AUCROC       50    0.698602       0.698652   0.708764              0.697606   \n",
       "             60    0.689374       0.732363   0.754242              0.726061   \n",
       "             70    0.685571       0.637302   0.688802              0.636183   \n",
       "             80    0.693861       0.748282   0.774921              0.739194   \n",
       "             90    0.696772       0.857833   0.861879              0.852490   \n",
       "AUCPRC       50    0.402790       0.401616   0.401706              0.401876   \n",
       "             60    0.507098       0.471307   0.469752              0.473537   \n",
       "             70    0.608329       0.637709   0.609767              0.638866   \n",
       "             80    0.708929       0.700982   0.688111              0.708530   \n",
       "             90    0.835555       0.817810   0.797772              0.826876   \n",
       "MCC          50    0.280693       0.287098   0.282380              0.286584   \n",
       "             60    0.228278       0.370232   0.367790              0.357579   \n",
       "             70    0.211630       0.155779   0.199882              0.154056   \n",
       "             80    0.121202       0.177087   0.160948              0.177052   \n",
       "             90    0.018030       0.233667   0.124158              0.232387   \n",
       "\n",
       "                  Proposed Ensemble  \n",
       "metric       run                     \n",
       "Testing_Time 50            0.621077  \n",
       "             60            0.504293  \n",
       "             70            0.501271  \n",
       "             80            0.734696  \n",
       "             90            1.306982  \n",
       "Accuracy     50           64.788360  \n",
       "             60           66.947637  \n",
       "             70           69.533333  \n",
       "             80           80.044444  \n",
       "             90           89.900000  \n",
       "AUCROC       50            0.689951  \n",
       "             60            0.712741  \n",
       "             70            0.644937  \n",
       "             80            0.715537  \n",
       "             90            0.815656  \n",
       "AUCPRC       50            0.406607  \n",
       "             60            0.490180  \n",
       "             70            0.630398  \n",
       "             80            0.707971  \n",
       "             90            0.808373  \n",
       "MCC          50            0.297544  \n",
       "             60            0.287403  \n",
       "             70            0.088062  \n",
       "             80            0.076044  \n",
       "             90            0.081446  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_analysis = pd.merge(german_rec_ideal, german_rec_60, on='algorithms',\n",
    "                suffixes=[\"_50\", \"_60\"])\n",
    "german_analysis = pd.merge(german_analysis, german_rec_70, on='algorithms')\n",
    "german_analysis = pd.merge(german_analysis, german_rec_80, on='algorithms',\n",
    "                suffixes=[\"_70\",\"_80\"])\n",
    "german_analysis = pd.merge(german_analysis, german_rec_90, on='algorithms')\n",
    "\n",
    "column_names = ['Testing_Time_50', 'Testing_Time_60',\n",
    "           'Testing_Time_70', 'Testing_Time_80',\n",
    "           'Testing_Time_90', 'Accuracy_50',\n",
    "            'Accuracy_60', 'Accuracy_70',\n",
    "           'Accuracy_80', 'Accuracy_90',\n",
    "            'AUCROC_50',  'AUCROC_60',\n",
    "            'AUCROC_70',  'AUCROC_80',\n",
    "            'AUCROC_90', 'AUCPRC_50',\n",
    "           'AUCPRC_60', 'AUCPRC_70',\n",
    "            'AUCPRC_80', 'AUCPRC_90',\n",
    "            'MCC_50', 'MCC_60',\n",
    "          'MCC_70', 'MCC_80',\n",
    "          'MCC_90']\n",
    "df_2 = german_analysis.reindex(columns=column_names)\n",
    "df_2 = df_2.T\n",
    "df_2 = df_2.rename_axis(\"Metrics\")\n",
    "df_2 = df_2.rename_axis('Models', axis='columns')\n",
    "\n",
    "df_2.columns = ['LR', 'KNN', 'Decision Tree',\n",
    "           'SVM', 'Naive Bayes', 'MLP',\n",
    "           'Random Forest', 'AdaBoost',\n",
    "           'Bagged Decision Tree',\n",
    "           'Proposed Ensemble']\n",
    "\n",
    "german_table=df_2.copy()\n",
    "german_table.index = pd.MultiIndex.from_product([['Testing_Time', 'Accuracy',\n",
    "                                    'AUCROC','AUCPRC',\n",
    "                                    'MCC'], \n",
    "                                    [50, 60, 70, 80, 90]],\n",
    "                                    names=['metric', 'run'])\n",
    "german_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LR_x</th>\n",
       "      <th>KNN_x</th>\n",
       "      <th>Decision Tree_x</th>\n",
       "      <th>SVM_x</th>\n",
       "      <th>Naive Bayes_x</th>\n",
       "      <th>MLP_x</th>\n",
       "      <th>Random Forest_x</th>\n",
       "      <th>AdaBoost_x</th>\n",
       "      <th>Bagged Decision Tree_x</th>\n",
       "      <th>Proposed Ensemble_x</th>\n",
       "      <th>LR_y</th>\n",
       "      <th>KNN_y</th>\n",
       "      <th>Decision Tree_y</th>\n",
       "      <th>SVM_y</th>\n",
       "      <th>Naive Bayes_y</th>\n",
       "      <th>MLP_y</th>\n",
       "      <th>Random Forest_y</th>\n",
       "      <th>AdaBoost_y</th>\n",
       "      <th>Bagged Decision Tree_y</th>\n",
       "      <th>Proposed Ensemble_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Testing_Time</th>\n",
       "      <th>50</th>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>1.026996</td>\n",
       "      <td>0.310644</td>\n",
       "      <td>0.129935</td>\n",
       "      <td>0.041460</td>\n",
       "      <td>0.326636</td>\n",
       "      <td>0.011434</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.044836</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.843754</td>\n",
       "      <td>0.297860</td>\n",
       "      <td>0.148712</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.621077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.014711</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.024569</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.427157</td>\n",
       "      <td>0.322857</td>\n",
       "      <td>0.147411</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.398497</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.042818</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.612007</td>\n",
       "      <td>0.315664</td>\n",
       "      <td>0.156433</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.504293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.013134</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.045837</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>2.057113</td>\n",
       "      <td>0.328691</td>\n",
       "      <td>0.153778</td>\n",
       "      <td>0.038836</td>\n",
       "      <td>0.586951</td>\n",
       "      <td>0.012043</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.036015</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.581282</td>\n",
       "      <td>0.384651</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>0.037770</td>\n",
       "      <td>0.501271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.015633</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.079072</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>2.833105</td>\n",
       "      <td>0.342097</td>\n",
       "      <td>0.158051</td>\n",
       "      <td>0.043202</td>\n",
       "      <td>0.976332</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.055970</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.710321</td>\n",
       "      <td>0.410798</td>\n",
       "      <td>0.168612</td>\n",
       "      <td>0.043788</td>\n",
       "      <td>0.734696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.021915</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.159118</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>6.507044</td>\n",
       "      <td>0.439832</td>\n",
       "      <td>0.233583</td>\n",
       "      <td>0.063877</td>\n",
       "      <td>1.573790</td>\n",
       "      <td>0.016936</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.120341</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>1.387405</td>\n",
       "      <td>0.423898</td>\n",
       "      <td>0.191314</td>\n",
       "      <td>0.050970</td>\n",
       "      <td>1.306982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Accuracy</th>\n",
       "      <th>50</th>\n",
       "      <td>86.277352</td>\n",
       "      <td>81.587099</td>\n",
       "      <td>80.560529</td>\n",
       "      <td>85.210997</td>\n",
       "      <td>85.601733</td>\n",
       "      <td>86.037226</td>\n",
       "      <td>84.292413</td>\n",
       "      <td>85.120063</td>\n",
       "      <td>83.223927</td>\n",
       "      <td>86.133134</td>\n",
       "      <td>64.947090</td>\n",
       "      <td>61.878307</td>\n",
       "      <td>64.259259</td>\n",
       "      <td>62.751323</td>\n",
       "      <td>63.280423</td>\n",
       "      <td>63.888889</td>\n",
       "      <td>64.206349</td>\n",
       "      <td>63.968254</td>\n",
       "      <td>64.074074</td>\n",
       "      <td>64.788360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>87.599415</td>\n",
       "      <td>84.082968</td>\n",
       "      <td>86.309211</td>\n",
       "      <td>87.216374</td>\n",
       "      <td>87.251827</td>\n",
       "      <td>87.913743</td>\n",
       "      <td>87.528143</td>\n",
       "      <td>86.867325</td>\n",
       "      <td>87.076754</td>\n",
       "      <td>87.495614</td>\n",
       "      <td>65.232832</td>\n",
       "      <td>66.036693</td>\n",
       "      <td>70.090137</td>\n",
       "      <td>62.180715</td>\n",
       "      <td>64.720012</td>\n",
       "      <td>64.404902</td>\n",
       "      <td>70.574958</td>\n",
       "      <td>70.434227</td>\n",
       "      <td>70.003438</td>\n",
       "      <td>66.947637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>88.976788</td>\n",
       "      <td>87.721252</td>\n",
       "      <td>88.714321</td>\n",
       "      <td>88.637016</td>\n",
       "      <td>88.872416</td>\n",
       "      <td>89.002420</td>\n",
       "      <td>90.464649</td>\n",
       "      <td>88.741798</td>\n",
       "      <td>90.021120</td>\n",
       "      <td>89.783465</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>67.133333</td>\n",
       "      <td>68.866667</td>\n",
       "      <td>70.200000</td>\n",
       "      <td>70.700000</td>\n",
       "      <td>71.633333</td>\n",
       "      <td>69.366667</td>\n",
       "      <td>71.233333</td>\n",
       "      <td>69.233333</td>\n",
       "      <td>69.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>89.783395</td>\n",
       "      <td>91.105476</td>\n",
       "      <td>92.116329</td>\n",
       "      <td>90.392216</td>\n",
       "      <td>90.392125</td>\n",
       "      <td>90.131708</td>\n",
       "      <td>93.230257</td>\n",
       "      <td>91.471695</td>\n",
       "      <td>93.056010</td>\n",
       "      <td>92.080243</td>\n",
       "      <td>79.888889</td>\n",
       "      <td>79.022222</td>\n",
       "      <td>78.911111</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>79.933333</td>\n",
       "      <td>79.244444</td>\n",
       "      <td>80.266667</td>\n",
       "      <td>79.155556</td>\n",
       "      <td>80.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90.415203</td>\n",
       "      <td>95.446780</td>\n",
       "      <td>96.186987</td>\n",
       "      <td>92.965930</td>\n",
       "      <td>91.912407</td>\n",
       "      <td>94.959696</td>\n",
       "      <td>96.779034</td>\n",
       "      <td>95.403242</td>\n",
       "      <td>96.422134</td>\n",
       "      <td>95.934434</td>\n",
       "      <td>90.033333</td>\n",
       "      <td>89.144444</td>\n",
       "      <td>89.311111</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>88.944444</td>\n",
       "      <td>89.900000</td>\n",
       "      <td>89.566667</td>\n",
       "      <td>90.044444</td>\n",
       "      <td>89.433333</td>\n",
       "      <td>89.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AUCROC</th>\n",
       "      <th>50</th>\n",
       "      <td>0.912817</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.815846</td>\n",
       "      <td>0.905881</td>\n",
       "      <td>0.904454</td>\n",
       "      <td>0.912431</td>\n",
       "      <td>0.891704</td>\n",
       "      <td>0.905529</td>\n",
       "      <td>0.881099</td>\n",
       "      <td>0.917078</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.654586</td>\n",
       "      <td>0.700722</td>\n",
       "      <td>0.682796</td>\n",
       "      <td>0.694402</td>\n",
       "      <td>0.698602</td>\n",
       "      <td>0.698652</td>\n",
       "      <td>0.708764</td>\n",
       "      <td>0.697606</td>\n",
       "      <td>0.689951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.922062</td>\n",
       "      <td>0.904998</td>\n",
       "      <td>0.869030</td>\n",
       "      <td>0.910774</td>\n",
       "      <td>0.909902</td>\n",
       "      <td>0.923223</td>\n",
       "      <td>0.933210</td>\n",
       "      <td>0.921727</td>\n",
       "      <td>0.920470</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>0.684956</td>\n",
       "      <td>0.681875</td>\n",
       "      <td>0.717562</td>\n",
       "      <td>0.655311</td>\n",
       "      <td>0.682131</td>\n",
       "      <td>0.689374</td>\n",
       "      <td>0.732363</td>\n",
       "      <td>0.754242</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.712741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.924094</td>\n",
       "      <td>0.916682</td>\n",
       "      <td>0.880095</td>\n",
       "      <td>0.903678</td>\n",
       "      <td>0.912331</td>\n",
       "      <td>0.926577</td>\n",
       "      <td>0.943073</td>\n",
       "      <td>0.931824</td>\n",
       "      <td>0.928978</td>\n",
       "      <td>0.944424</td>\n",
       "      <td>0.683397</td>\n",
       "      <td>0.614254</td>\n",
       "      <td>0.632040</td>\n",
       "      <td>0.643317</td>\n",
       "      <td>0.684984</td>\n",
       "      <td>0.685571</td>\n",
       "      <td>0.637302</td>\n",
       "      <td>0.688802</td>\n",
       "      <td>0.636183</td>\n",
       "      <td>0.644937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.924294</td>\n",
       "      <td>0.914964</td>\n",
       "      <td>0.892729</td>\n",
       "      <td>0.893570</td>\n",
       "      <td>0.913862</td>\n",
       "      <td>0.931888</td>\n",
       "      <td>0.953827</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.938054</td>\n",
       "      <td>0.949142</td>\n",
       "      <td>0.693926</td>\n",
       "      <td>0.686375</td>\n",
       "      <td>0.739458</td>\n",
       "      <td>0.592491</td>\n",
       "      <td>0.697657</td>\n",
       "      <td>0.693861</td>\n",
       "      <td>0.748282</td>\n",
       "      <td>0.774921</td>\n",
       "      <td>0.739194</td>\n",
       "      <td>0.715537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.922955</td>\n",
       "      <td>0.921942</td>\n",
       "      <td>0.904013</td>\n",
       "      <td>0.831236</td>\n",
       "      <td>0.913949</td>\n",
       "      <td>0.937886</td>\n",
       "      <td>0.961345</td>\n",
       "      <td>0.937355</td>\n",
       "      <td>0.947146</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.699936</td>\n",
       "      <td>0.785263</td>\n",
       "      <td>0.845718</td>\n",
       "      <td>0.497895</td>\n",
       "      <td>0.706311</td>\n",
       "      <td>0.696772</td>\n",
       "      <td>0.857833</td>\n",
       "      <td>0.861879</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>0.815656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AUCPRC</th>\n",
       "      <th>50</th>\n",
       "      <td>0.910748</td>\n",
       "      <td>0.855522</td>\n",
       "      <td>0.771629</td>\n",
       "      <td>0.903514</td>\n",
       "      <td>0.893326</td>\n",
       "      <td>0.912102</td>\n",
       "      <td>0.881913</td>\n",
       "      <td>0.900651</td>\n",
       "      <td>0.860225</td>\n",
       "      <td>0.917297</td>\n",
       "      <td>0.402161</td>\n",
       "      <td>0.428220</td>\n",
       "      <td>0.399915</td>\n",
       "      <td>0.408298</td>\n",
       "      <td>0.404811</td>\n",
       "      <td>0.402790</td>\n",
       "      <td>0.401616</td>\n",
       "      <td>0.401706</td>\n",
       "      <td>0.401876</td>\n",
       "      <td>0.406607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.940329</td>\n",
       "      <td>0.913132</td>\n",
       "      <td>0.869727</td>\n",
       "      <td>0.923893</td>\n",
       "      <td>0.926487</td>\n",
       "      <td>0.941639</td>\n",
       "      <td>0.945419</td>\n",
       "      <td>0.934846</td>\n",
       "      <td>0.927450</td>\n",
       "      <td>0.950691</td>\n",
       "      <td>0.508227</td>\n",
       "      <td>0.518705</td>\n",
       "      <td>0.476411</td>\n",
       "      <td>0.519639</td>\n",
       "      <td>0.509854</td>\n",
       "      <td>0.507098</td>\n",
       "      <td>0.471307</td>\n",
       "      <td>0.469752</td>\n",
       "      <td>0.473537</td>\n",
       "      <td>0.490180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.959278</td>\n",
       "      <td>0.943428</td>\n",
       "      <td>0.914751</td>\n",
       "      <td>0.939044</td>\n",
       "      <td>0.951690</td>\n",
       "      <td>0.961669</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>0.961244</td>\n",
       "      <td>0.952170</td>\n",
       "      <td>0.970591</td>\n",
       "      <td>0.609014</td>\n",
       "      <td>0.656924</td>\n",
       "      <td>0.636384</td>\n",
       "      <td>0.625024</td>\n",
       "      <td>0.608345</td>\n",
       "      <td>0.608329</td>\n",
       "      <td>0.637709</td>\n",
       "      <td>0.609767</td>\n",
       "      <td>0.638866</td>\n",
       "      <td>0.630398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.974295</td>\n",
       "      <td>0.962773</td>\n",
       "      <td>0.951541</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.970675</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>0.982676</td>\n",
       "      <td>0.976501</td>\n",
       "      <td>0.973805</td>\n",
       "      <td>0.983210</td>\n",
       "      <td>0.710032</td>\n",
       "      <td>0.737655</td>\n",
       "      <td>0.713571</td>\n",
       "      <td>0.745290</td>\n",
       "      <td>0.709652</td>\n",
       "      <td>0.708929</td>\n",
       "      <td>0.700982</td>\n",
       "      <td>0.688111</td>\n",
       "      <td>0.708530</td>\n",
       "      <td>0.707971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.987673</td>\n",
       "      <td>0.983572</td>\n",
       "      <td>0.979490</td>\n",
       "      <td>0.961498</td>\n",
       "      <td>0.986461</td>\n",
       "      <td>0.989866</td>\n",
       "      <td>0.992438</td>\n",
       "      <td>0.989576</td>\n",
       "      <td>0.989129</td>\n",
       "      <td>0.991213</td>\n",
       "      <td>0.835157</td>\n",
       "      <td>0.849818</td>\n",
       "      <td>0.834729</td>\n",
       "      <td>0.885927</td>\n",
       "      <td>0.834336</td>\n",
       "      <td>0.835555</td>\n",
       "      <td>0.817810</td>\n",
       "      <td>0.797772</td>\n",
       "      <td>0.826876</td>\n",
       "      <td>0.808373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MCC</th>\n",
       "      <th>50</th>\n",
       "      <td>0.729591</td>\n",
       "      <td>0.637456</td>\n",
       "      <td>0.613734</td>\n",
       "      <td>0.706590</td>\n",
       "      <td>0.714595</td>\n",
       "      <td>0.724285</td>\n",
       "      <td>0.688354</td>\n",
       "      <td>0.705387</td>\n",
       "      <td>0.667852</td>\n",
       "      <td>0.725687</td>\n",
       "      <td>0.300088</td>\n",
       "      <td>0.240515</td>\n",
       "      <td>0.287119</td>\n",
       "      <td>0.256975</td>\n",
       "      <td>0.269833</td>\n",
       "      <td>0.280693</td>\n",
       "      <td>0.287098</td>\n",
       "      <td>0.282380</td>\n",
       "      <td>0.286584</td>\n",
       "      <td>0.297544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.740451</td>\n",
       "      <td>0.671094</td>\n",
       "      <td>0.717330</td>\n",
       "      <td>0.732571</td>\n",
       "      <td>0.734376</td>\n",
       "      <td>0.747586</td>\n",
       "      <td>0.740755</td>\n",
       "      <td>0.726727</td>\n",
       "      <td>0.732664</td>\n",
       "      <td>0.738898</td>\n",
       "      <td>0.236003</td>\n",
       "      <td>0.260763</td>\n",
       "      <td>0.359771</td>\n",
       "      <td>0.153221</td>\n",
       "      <td>0.222988</td>\n",
       "      <td>0.228278</td>\n",
       "      <td>0.370232</td>\n",
       "      <td>0.367790</td>\n",
       "      <td>0.357579</td>\n",
       "      <td>0.287403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.735551</td>\n",
       "      <td>0.701883</td>\n",
       "      <td>0.733223</td>\n",
       "      <td>0.726683</td>\n",
       "      <td>0.734868</td>\n",
       "      <td>0.738371</td>\n",
       "      <td>0.771436</td>\n",
       "      <td>0.730676</td>\n",
       "      <td>0.761208</td>\n",
       "      <td>0.752851</td>\n",
       "      <td>0.194953</td>\n",
       "      <td>0.082433</td>\n",
       "      <td>0.119018</td>\n",
       "      <td>0.116253</td>\n",
       "      <td>0.179344</td>\n",
       "      <td>0.211630</td>\n",
       "      <td>0.155779</td>\n",
       "      <td>0.199882</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.088062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.682806</td>\n",
       "      <td>0.711251</td>\n",
       "      <td>0.755454</td>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.707195</td>\n",
       "      <td>0.700272</td>\n",
       "      <td>0.785582</td>\n",
       "      <td>0.726669</td>\n",
       "      <td>0.781802</td>\n",
       "      <td>0.743790</td>\n",
       "      <td>0.123845</td>\n",
       "      <td>0.121806</td>\n",
       "      <td>0.144181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181599</td>\n",
       "      <td>0.121202</td>\n",
       "      <td>0.177087</td>\n",
       "      <td>0.160948</td>\n",
       "      <td>0.177052</td>\n",
       "      <td>0.076044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.488405</td>\n",
       "      <td>0.731192</td>\n",
       "      <td>0.786649</td>\n",
       "      <td>0.521325</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>0.684441</td>\n",
       "      <td>0.815834</td>\n",
       "      <td>0.726360</td>\n",
       "      <td>0.796702</td>\n",
       "      <td>0.753873</td>\n",
       "      <td>0.094284</td>\n",
       "      <td>0.130314</td>\n",
       "      <td>0.189921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148803</td>\n",
       "      <td>0.018030</td>\n",
       "      <td>0.233667</td>\n",
       "      <td>0.124158</td>\n",
       "      <td>0.232387</td>\n",
       "      <td>0.081446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       LR_x      KNN_x  Decision Tree_x      SVM_x  \\\n",
       "metric       run                                                     \n",
       "Testing_Time 50    0.014702   0.003967         0.004201   0.010767   \n",
       "             60    0.014711   0.005801         0.003667   0.024569   \n",
       "             70    0.013134   0.004533         0.004034   0.045837   \n",
       "             80    0.015633   0.005567         0.005233   0.079072   \n",
       "             90    0.021915   0.008590         0.007500   0.159118   \n",
       "Accuracy     50   86.277352  81.587099        80.560529  85.210997   \n",
       "             60   87.599415  84.082968        86.309211  87.216374   \n",
       "             70   88.976788  87.721252        88.714321  88.637016   \n",
       "             80   89.783395  91.105476        92.116329  90.392216   \n",
       "             90   90.415203  95.446780        96.186987  92.965930   \n",
       "AUCROC       50    0.912817   0.874486         0.815846   0.905881   \n",
       "             60    0.922062   0.904998         0.869030   0.910774   \n",
       "             70    0.924094   0.916682         0.880095   0.903678   \n",
       "             80    0.924294   0.914964         0.892729   0.893570   \n",
       "             90    0.922955   0.921942         0.904013   0.831236   \n",
       "AUCPRC       50    0.910748   0.855522         0.771629   0.903514   \n",
       "             60    0.940329   0.913132         0.869727   0.923893   \n",
       "             70    0.959278   0.943428         0.914751   0.939044   \n",
       "             80    0.974295   0.962773         0.951541   0.956667   \n",
       "             90    0.987673   0.983572         0.979490   0.961498   \n",
       "MCC          50    0.729591   0.637456         0.613734   0.706590   \n",
       "             60    0.740451   0.671094         0.717330   0.732571   \n",
       "             70    0.735551   0.701883         0.733223   0.726683   \n",
       "             80    0.682806   0.711251         0.755454   0.706485   \n",
       "             90    0.488405   0.731192         0.786649   0.521325   \n",
       "\n",
       "                  Naive Bayes_x      MLP_x  Random Forest_x  AdaBoost_x  \\\n",
       "metric       run                                                          \n",
       "Testing_Time 50        0.002967   1.026996         0.310644    0.129935   \n",
       "             60        0.003200   1.427157         0.322857    0.147411   \n",
       "             70        0.003267   2.057113         0.328691    0.153778   \n",
       "             80        0.003334   2.833105         0.342097    0.158051   \n",
       "             90        0.004734   6.507044         0.439832    0.233583   \n",
       "Accuracy     50       85.601733  86.037226        84.292413   85.120063   \n",
       "             60       87.251827  87.913743        87.528143   86.867325   \n",
       "             70       88.872416  89.002420        90.464649   88.741798   \n",
       "             80       90.392125  90.131708        93.230257   91.471695   \n",
       "             90       91.912407  94.959696        96.779034   95.403242   \n",
       "AUCROC       50        0.904454   0.912431         0.891704    0.905529   \n",
       "             60        0.909902   0.923223         0.933210    0.921727   \n",
       "             70        0.912331   0.926577         0.943073    0.931824   \n",
       "             80        0.913862   0.931888         0.953827    0.932200   \n",
       "             90        0.913949   0.937886         0.961345    0.937355   \n",
       "AUCPRC       50        0.893326   0.912102         0.881913    0.900651   \n",
       "             60        0.926487   0.941639         0.945419    0.934846   \n",
       "             70        0.951690   0.961669         0.965820    0.961244   \n",
       "             80        0.970675   0.977666         0.982676    0.976501   \n",
       "             90        0.986461   0.989866         0.992438    0.989576   \n",
       "MCC          50        0.714595   0.724285         0.688354    0.705387   \n",
       "             60        0.734376   0.747586         0.740755    0.726727   \n",
       "             70        0.734868   0.738371         0.771436    0.730676   \n",
       "             80        0.707195   0.700272         0.785582    0.726669   \n",
       "             90        0.626250   0.684441         0.815834    0.726360   \n",
       "\n",
       "                  Bagged Decision Tree_x  Proposed Ensemble_x       LR_y  \\\n",
       "metric       run                                                           \n",
       "Testing_Time 50                 0.041460             0.326636   0.011434   \n",
       "             60                 0.037469             0.398497   0.009613   \n",
       "             70                 0.038836             0.586951   0.012043   \n",
       "             80                 0.043202             0.976332   0.012034   \n",
       "             90                 0.063877             1.573790   0.016936   \n",
       "Accuracy     50                83.223927            86.133134  64.947090   \n",
       "             60                87.076754            87.495614  65.232832   \n",
       "             70                90.021120            89.783465  71.500000   \n",
       "             80                93.056010            92.080243  79.888889   \n",
       "             90                96.422134            95.934434  90.033333   \n",
       "AUCROC       50                 0.881099             0.917078   0.696175   \n",
       "             60                 0.920470             0.935103   0.684956   \n",
       "             70                 0.928978             0.944424   0.683397   \n",
       "             80                 0.938054             0.949142   0.693926   \n",
       "             90                 0.947146             0.953488   0.699936   \n",
       "AUCPRC       50                 0.860225             0.917297   0.402161   \n",
       "             60                 0.927450             0.950691   0.508227   \n",
       "             70                 0.952170             0.970591   0.609014   \n",
       "             80                 0.973805             0.983210   0.710032   \n",
       "             90                 0.989129             0.991213   0.835157   \n",
       "MCC          50                 0.667852             0.725687   0.300088   \n",
       "             60                 0.732664             0.738898   0.236003   \n",
       "             70                 0.761208             0.752851   0.194953   \n",
       "             80                 0.781802             0.743790   0.123845   \n",
       "             90                 0.796702             0.753873   0.094284   \n",
       "\n",
       "                      KNN_y  Decision Tree_y      SVM_y  Naive Bayes_y  \\\n",
       "metric       run                                                         \n",
       "Testing_Time 50    0.003667         0.003601   0.044836       0.003067   \n",
       "             60    0.003467         0.003000   0.042818       0.004156   \n",
       "             70    0.003657         0.002469   0.036015       0.004125   \n",
       "             80    0.003667         0.003467   0.055970       0.003700   \n",
       "             90    0.006500         0.005900   0.120341       0.003567   \n",
       "Accuracy     50   61.878307        64.259259  62.751323      63.280423   \n",
       "             60   66.036693        70.090137  62.180715      64.720012   \n",
       "             70   67.133333        68.866667  70.200000      70.700000   \n",
       "             80   79.022222        78.911111  80.000000      79.666667   \n",
       "             90   89.144444        89.311111  90.000000      88.944444   \n",
       "AUCROC       50    0.654586         0.700722   0.682796       0.694402   \n",
       "             60    0.681875         0.717562   0.655311       0.682131   \n",
       "             70    0.614254         0.632040   0.643317       0.684984   \n",
       "             80    0.686375         0.739458   0.592491       0.697657   \n",
       "             90    0.785263         0.845718   0.497895       0.706311   \n",
       "AUCPRC       50    0.428220         0.399915   0.408298       0.404811   \n",
       "             60    0.518705         0.476411   0.519639       0.509854   \n",
       "             70    0.656924         0.636384   0.625024       0.608345   \n",
       "             80    0.737655         0.713571   0.745290       0.709652   \n",
       "             90    0.849818         0.834729   0.885927       0.834336   \n",
       "MCC          50    0.240515         0.287119   0.256975       0.269833   \n",
       "             60    0.260763         0.359771   0.153221       0.222988   \n",
       "             70    0.082433         0.119018   0.116253       0.179344   \n",
       "             80    0.121806         0.144181   0.000000       0.181599   \n",
       "             90    0.130314         0.189921   0.000000       0.148803   \n",
       "\n",
       "                      MLP_y  Random Forest_y  AdaBoost_y  \\\n",
       "metric       run                                           \n",
       "Testing_Time 50    0.843754         0.297860    0.148712   \n",
       "             60    0.612007         0.315664    0.156433   \n",
       "             70    0.581282         0.384651    0.205749   \n",
       "             80    0.710321         0.410798    0.168612   \n",
       "             90    1.387405         0.423898    0.191314   \n",
       "Accuracy     50   63.888889        64.206349   63.968254   \n",
       "             60   64.404902        70.574958   70.434227   \n",
       "             70   71.633333        69.366667   71.233333   \n",
       "             80   79.933333        79.244444   80.266667   \n",
       "             90   89.900000        89.566667   90.044444   \n",
       "AUCROC       50    0.698602         0.698652    0.708764   \n",
       "             60    0.689374         0.732363    0.754242   \n",
       "             70    0.685571         0.637302    0.688802   \n",
       "             80    0.693861         0.748282    0.774921   \n",
       "             90    0.696772         0.857833    0.861879   \n",
       "AUCPRC       50    0.402790         0.401616    0.401706   \n",
       "             60    0.507098         0.471307    0.469752   \n",
       "             70    0.608329         0.637709    0.609767   \n",
       "             80    0.708929         0.700982    0.688111   \n",
       "             90    0.835555         0.817810    0.797772   \n",
       "MCC          50    0.280693         0.287098    0.282380   \n",
       "             60    0.228278         0.370232    0.367790   \n",
       "             70    0.211630         0.155779    0.199882   \n",
       "             80    0.121202         0.177087    0.160948   \n",
       "             90    0.018030         0.233667    0.124158   \n",
       "\n",
       "                  Bagged Decision Tree_y  Proposed Ensemble_y  \n",
       "metric       run                                               \n",
       "Testing_Time 50                 0.038334             0.621077  \n",
       "             60                 0.032955             0.504293  \n",
       "             70                 0.037770             0.501271  \n",
       "             80                 0.043788             0.734696  \n",
       "             90                 0.050970             1.306982  \n",
       "Accuracy     50                64.074074            64.788360  \n",
       "             60                70.003438            66.947637  \n",
       "             70                69.233333            69.533333  \n",
       "             80                79.155556            80.044444  \n",
       "             90                89.433333            89.900000  \n",
       "AUCROC       50                 0.697606             0.689951  \n",
       "             60                 0.726061             0.712741  \n",
       "             70                 0.636183             0.644937  \n",
       "             80                 0.739194             0.715537  \n",
       "             90                 0.852490             0.815656  \n",
       "AUCPRC       50                 0.401876             0.406607  \n",
       "             60                 0.473537             0.490180  \n",
       "             70                 0.638866             0.630398  \n",
       "             80                 0.708530             0.707971  \n",
       "             90                 0.826876             0.808373  \n",
       "MCC          50                 0.286584             0.297544  \n",
       "             60                 0.357579             0.287403  \n",
       "             70                 0.154056             0.088062  \n",
       "             80                 0.177052             0.076044  \n",
       "             90                 0.232387             0.081446  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.merge(df, df_2, on='Metrics')\n",
    "final_df.index = pd.MultiIndex.from_product([['Testing_Time', 'Accuracy',\n",
    "                                    'AUCROC','AUCPRC',\n",
    "                                    'MCC'], \n",
    "                                    [50, 60, 70, 80, 90]],\n",
    "                                    names=['metric', 'run'])\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "The next step is to create visualizations from the data collected from the results and show the performances of the different algorithms across both datasets and show which algorithm(s) performed best and try to determine why. For the above dataframe, it can be noticed that the aussie part of the data which is X suffixed looks as we would expect, but the german part of the data has inconsistent results in terms of performance of the algorithms. This suggests that there may be something wrong with the dataset set such that the algorithms are learning the wrong function. Visualization might confirm this suspicion or the dataset can be switched to the other german dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aussie_table.to_csv('aussie_results.csv', index=False)\n",
    "german_table.to_csv('german_results.csv', index=False)\n",
    "final_df.to_csv('final_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a63892120075ef855a1524b61526a355804231303da13645b450f19f7b5bb515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
